import time
import uuid
import json
import csv
import random
from statistics import mean
from concurrent.futures import ThreadPoolExecutor
from pymongo import MongoClient
import requests
from arango import ArangoClient
from couchbase.cluster import Cluster
from couchbase.options import ClusterOptions
from couchbase.auth import PasswordAuthenticator
from couchbase.management.buckets import CreateBucketSettings
from couchbase.exceptions import BucketAlreadyExistsException
import matplotlib.pyplot as plt
import pandas as pd

DOCUMENT_SIZES = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]
THREADS = 10
TEST_DOC = {
    "name": "Test",
    "value": 123,
    "uuid": None  # –±—É–¥–µ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏—Å—è —É –∫–æ–∂–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
}

# –°—Ü–µ–Ω–∞—Ä—ñ—ó –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: –∑–∞–ø–∏—Å/—á–∏—Ç–∞–Ω–Ω—è —É –≤—ñ–¥—Å–æ—Ç–∫–∞—Ö
WORKLOAD_SCENARIOS = [
    {"name": "read_heavy", "read": 90, "write": 10, "description": "90% —á–∏—Ç–∞–Ω–Ω—è, 10% –∑–∞–ø–∏—Å—É"},
    {"name": "balanced", "read": 50, "write": 50, "description": "50% —á–∏—Ç–∞–Ω–Ω—è, 50% –∑–∞–ø–∏—Å—É"},
    {"name": "write_heavy", "read": 10, "write": 90, "description": "10% —á–∏—Ç–∞–Ω–Ω—è, 90% –∑–∞–ø–∏—Å—É"}
]

def create_test_doc():
    doc = TEST_DOC.copy()
    doc["uuid"] = str(uuid.uuid4())
    return doc

def insert_parallel(fn_insert, num_docs, db_name):
    docs = [create_test_doc() for _ in range(num_docs)]

    start = time.time()
    with ThreadPoolExecutor(max_workers=THREADS) as executor:
        futures = [executor.submit(fn_insert, doc) for doc in docs]
        for future in futures:
            future.result()
    total_time = time.time() - start
    print(f"[{db_name}] Insert {num_docs} docs done in {total_time:.2f}s")
    return total_time, total_time / num_docs

def read_parallel(fn_read, num_docs, db_name):
    start = time.time()
    with ThreadPoolExecutor(max_workers=THREADS) as executor:
        futures = [executor.submit(fn_read) for _ in range(num_docs)]
        for future in futures:
            future.result()
    total_time = time.time() - start
    print(f"[{db_name}] Read {num_docs} docs done in {total_time:.2f}s")
    return total_time, total_time / num_docs

def mixed_workload_parallel(fn_insert, fn_read, num_ops, read_pct, write_pct, db_name):
    read_ops = int(num_ops * (read_pct / 100))
    write_ops = num_ops - read_ops
    
    ops = []
    # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –æ–ø–µ—Ä–∞—Ü—ñ—ó –∑–∞–ø–∏—Å—É
    for _ in range(write_ops):
        doc = create_test_doc()
        ops.append(("write", doc))
    
    # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –æ–ø–µ—Ä–∞—Ü—ñ—ó —á–∏—Ç–∞–Ω–Ω—è
    for _ in range(read_ops):
        ops.append(("read", None))
    
    # –ü–µ—Ä–µ–º—ñ—à–∞—Ç–∏ –æ–ø–µ—Ä–∞—Ü—ñ—ó –¥–ª—è —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ—à–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    random.shuffle(ops)
    
    start = time.time()
    with ThreadPoolExecutor(max_workers=THREADS) as executor:
        futures = []
        for op_type, doc in ops:
            if op_type == "write":
                futures.append(executor.submit(fn_insert, doc))
            else:
                futures.append(executor.submit(fn_read))
        
        for future in futures:
            future.result()
    
    total_time = time.time() - start
    print(f"[{db_name}] Mixed workload ({read_pct}% read, {write_pct}% write) - {num_ops} ops done in {total_time:.2f}s")
    return total_time, total_time / num_ops

def benchmark_mongo(num_docs, scenario=None):
    print(f"[MongoDB] Connecting...")
    client = MongoClient("mongodb://localhost:27017/")
    db = client.benchmark
    collection = db.test
    collection.delete_many({})  # Clean

    insert_fn = lambda doc: collection.insert_one(doc)
    read_fn = lambda: list(collection.find({"name": "Test"}))

    if scenario:
        # –ó–º—ñ—à–∞–Ω–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        workload_time, avg_op_time = mixed_workload_parallel(
            insert_fn, read_fn, num_docs, 
            scenario["read"], scenario["write"], f"MongoDB - {scenario['description']}"
        )
        return workload_time, avg_op_time
    else:
        # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ä–æ–∑–¥—ñ–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        insert_time, avg_insert = insert_parallel(insert_fn, num_docs, "MongoDB")
        read_time, avg_read = read_parallel(read_fn, num_docs, "MongoDB")
        return insert_time, read_time, avg_insert, avg_read

# def benchmark_couchdb(num_docs, scenario=None):
#     print(f"[CouchDB] Connecting...")
#     base_url = "http://admin:admin@localhost:5984/benchmark"
#     requests.put(base_url)
#     headers = {"Content-Type": "application/json"}
# 
#     def insert(doc):
#         requests.post(base_url, headers=headers, data=json.dumps(doc))
# 
#     def read():
#         requests.get(base_url + "/_all_docs?include_docs=true")
# 
#     if scenario:
#         # –ó–º—ñ—à–∞–Ω–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
#         workload_time, avg_op_time = mixed_workload_parallel(
#             insert, read, num_docs, 
#             scenario["read"], scenario["write"], f"CouchDB - {scenario['description']}"
#         )
#         return workload_time, avg_op_time
#     else:
#         # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ä–æ–∑–¥—ñ–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
#         insert_time, avg_insert = insert_parallel(insert, num_docs, "CouchDB")
#         read_time, avg_read = read_parallel(read, num_docs, "CouchDB")
#         return insert_time, read_time, avg_insert, avg_read

def benchmark_arango(num_docs, scenario=None):
    print(f"[ArangoDB] Connecting...")
    client = ArangoClient()
    db = client.db('_system', username='root', password='admin')

    if not db.has_database('benchmark'):
        db.create_database('benchmark')
    db = client.db('benchmark', username='root', password='admin')

    if db.has_collection('test'):
        db.delete_collection('test')
    col = db.create_collection('test')

    insert_fn = lambda doc: col.insert(doc)
    read_fn = lambda: list(col.find({"name": "Test"}))

    if scenario:
        # –ó–º—ñ—à–∞–Ω–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        workload_time, avg_op_time = mixed_workload_parallel(
            insert_fn, read_fn, num_docs, 
            scenario["read"], scenario["write"], f"ArangoDB - {scenario['description']}"
        )
        return workload_time, avg_op_time
    else:
        # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ä–æ–∑–¥—ñ–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        insert_time, avg_insert = insert_parallel(insert_fn, num_docs, "ArangoDB")
        read_time, avg_read = read_parallel(read_fn, num_docs, "ArangoDB")
        return insert_time, read_time, avg_insert, avg_read

def benchmark_couchbase(num_docs, scenario=None):
    print(f"[Couchbase] Connecting...")
    cluster = Cluster("couchbase://localhost", ClusterOptions(
        PasswordAuthenticator("admin", "admin123")))
    bucket_name = "benchmark"
    try:
        cluster.buckets().create_bucket(CreateBucketSettings(name=bucket_name, ram_quota_mb=100))
    except BucketAlreadyExistsException:
        pass

    bucket = cluster.bucket(bucket_name)
    collection = bucket.default_collection()

    inserted_keys = []

    def insert(doc):
        key = str(uuid.uuid4())
        collection.upsert(key, doc)
        inserted_keys.append(key)

    def read():
        if inserted_keys:
            key = random.choice(inserted_keys)
            try:
                collection.get(key)
            except Exception:
                pass  # –Ø–∫—â–æ —â–æ—Å—å –ø—ñ—à–ª–æ –Ω–µ —Ç–∞–∫ ‚Äî –ø—Ä–æ—Å—Ç–æ —ñ–≥–Ω–æ—Ä—É—î–º–æ

    if scenario:
        # –î–ª—è –∑–º—ñ—à–∞–Ω–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–º –ø–æ—Ç—Ä—ñ–±–Ω–æ —Å–ø–æ—á–∞—Ç–∫—É –≤—Å—Ç–∞–≤–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è
        pre_inserted = min(100, num_docs)  # –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –≤—Å—Ç–∞–≤–∏—Ç–∏ –¥–µ—è–∫—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è
        for _ in range(pre_inserted):
            insert(create_test_doc())
        
        # –ó–º—ñ—à–∞–Ω–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
        workload_time, avg_op_time = mixed_workload_parallel(
            insert, read, num_docs, 
            scenario["read"], scenario["write"], f"Couchbase - {scenario['description']}"
        )
        return workload_time, avg_op_time
    else:
        # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ä–æ–∑–¥—ñ–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        insert_time, avg_insert = insert_parallel(insert, num_docs, "Couchbase")
        read_time, avg_read = read_parallel(read, num_docs, "Couchbase")
        return insert_time, read_time, avg_insert, avg_read

def save_results(results, filename="benchmark_pro_results.csv"):
    with open(filename, mode="w", newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Database", "Documents", "Insert Time (s)", "Read Time (s)",
                         "Avg Insert Latency (s)", "Avg Read Latency (s)"])
        for row in results:
            writer.writerow(row)
    print(f"\n‚úÖ Results saved to {filename}")

def plot_workload_results(results_df):
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≥—Ä–∞—Ñ—ñ–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä—ñ—é –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    scenarios = results_df['Scenario'].unique()
    
    for scenario in scenarios:
        plt.figure(figsize=(12, 6))
        scenario_data = results_df[results_df['Scenario'] == scenario]
        
        for db in scenario_data['Database'].unique():
            db_data = scenario_data[scenario_data['Database'] == db]
            plt.plot(db_data['Documents'], db_data['Avg Operation Latency (s)'], 
                    marker='o', label=db)
        
        plt.title(f'–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –æ–ø–µ—Ä–∞—Ü—ñ—ó –¥–ª—è —Å—Ü–µ–Ω–∞—Ä—ñ—é: {scenario}')
        plt.xlabel('–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü—ñ–π')
        plt.ylabel('–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –æ–ø–µ—Ä–∞—Ü—ñ—ó (—Å–µ–∫—É–Ω–¥–∏)')
        plt.xscale('log', base=2)
        plt.grid(True)
        plt.legend()
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≥—Ä–∞—Ñ—ñ–∫ —É –∫–æ—Ä–µ–Ω–µ–≤—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
        filename = f'benchmark_{scenario.lower().replace(" ", "_")}.png'
        plt.savefig(filename)
        plt.close()
        print(f"‚úÖ –ì—Ä–∞—Ñ—ñ–∫ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–∞–π–ª: {filename}")

def save_workload_results(results, filename="benchmark_workload_results.csv"):
    with open(filename, mode="w", newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["Database", "Scenario", "Documents", "Total Time (s)", "Avg Operation Latency (s)"])
        for row in results:
            writer.writerow(row)
    print(f"\n‚úÖ Results saved to {filename}")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≥—Ä–∞—Ñ—ñ–∫–∏
    results_df = pd.read_csv(filename, encoding='utf-8')
    plot_workload_results(results_df)
    print("\n‚úÖ –ì—Ä–∞—Ñ—ñ–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–∞–π–ª–∏ benchmark_*.png")

def run_benchmark_pro():
    all_results = []

    for num_docs in DOCUMENT_SIZES:
        print(f"\nüöÄ Benchmarking {num_docs} documents...\n")

        all_results.append(["MongoDB", num_docs] + list(benchmark_mongo(num_docs)))
        # all_results.append(["CouchDB", num_docs] + list(benchmark_couchdb(num_docs)))
        all_results.append(["ArangoDB", num_docs] + list(benchmark_arango(num_docs)))
        all_results.append(["Couchbase", num_docs] + list(benchmark_couchbase(num_docs)))

    save_results(all_results)

def run_workload_benchmarks():
    all_results = []
    
    for scenario in WORKLOAD_SCENARIOS:
        print(f"\nüöÄ Running {scenario['description']} benchmark...\n")
        
        for num_docs in DOCUMENT_SIZES:
            print(f"\nüìä Testing with {num_docs} operations...\n")
            
            # MongoDB
            time_mongo, avg_mongo = benchmark_mongo(num_docs, scenario)
            all_results.append(["MongoDB", scenario['description'], num_docs, time_mongo, avg_mongo])
            
            # CouchDB
            # time_couch, avg_couch = benchmark_couchdb(num_docs, scenario)
            # all_results.append(["CouchDB", scenario['description'], num_docs, time_couch, avg_couch])
            
            # ArangoDB
            time_arango, avg_arango = benchmark_arango(num_docs, scenario)
            all_results.append(["ArangoDB", scenario['description'], num_docs, time_arango, avg_arango])
            
            # Couchbase
            time_couchbase, avg_couchbase = benchmark_couchbase(num_docs, scenario)
            all_results.append(["Couchbase", scenario['description'], num_docs, time_couchbase, avg_couchbase])
    
    save_workload_results(all_results)

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫—ñ–≤...")
    run_benchmark_pro()  # –ó–∞–ø—É—Å–∫–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –±–µ–Ω—á–º–∞—Ä–∫
    run_workload_benchmarks()  # –ó–∞–ø—É—Å–∫–∞—î–º–æ –±–µ–Ω—á–º–∞—Ä–∫ –∑ —Ä—ñ–∑–Ω–∏–º–∏ —Å—Ü–µ–Ω–∞—Ä—ñ—è–º–∏ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    print("\n‚úÖ –í—Å—ñ –±–µ–Ω—á–º–∞—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
